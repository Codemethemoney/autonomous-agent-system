{
    "name": "ollama",
    "type": "llm",
    "enabled": true,
    "config": {
        "base_url": "http://localhost:11434",
        "model": "llama2",
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.9,
            "max_tokens": 2048
        }
    },
    "capabilities": {
        "code_generation": true,
        "code_analysis": true,
        "tool_use": true
    }
}
